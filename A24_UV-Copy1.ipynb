{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d5f9e8-d274-4588-b15e-d92b82e9974d",
   "metadata": {},
   "source": [
    "# Cali Pfleger\n",
    "## 05/25/2024\n",
    "- Model iCESM and CESM Last Millenium Ensemble \n",
    "- Climate System: Pacific Walker Circulation \n",
    "- Index: Sea Level Pressure Index (hPa)\n",
    "- Variable: d18Op (0/00) (per mille)\n",
    "- Time period: 1850-2005 \n",
    "- Forcings: Full, GHG, LULC, OZA\n",
    "\n",
    "# Calculations:\n",
    "- Index Time Series (trend line, p-value, standered error (+1/-1) ribbon and ensmeble average)\n",
    "- Climatological Average Maps\n",
    "- Global Average Time Series (standered error ribbon and ensmeble average)\n",
    "- Linear Trend Maps (95% CI significance stippling)- \n",
    "- Correlation with Index Maps (95% CI significance stippling)- \n",
    "- Effect of Forcing Maps (Correlation - PI Control Run Corrleation)\n",
    "GCM Changes in Vertical Velocity (ω) Across the Tropical Pacific.\n",
    "iCAM5 = 2xCO2 Experiment minus Modern Control, Meridional Mean (−20 to 20 latitude).Change in vertical velocity (ω) in the experiment minus the control in color filled contour plot. Black contour lines show control simulation. Sign convention is negative = upward motion, positive = downward motion. Thus, red colors in Western Pacific indicate a reduction in the magnitude of the negative values in the control compared to the experiment. Blue colors indicate less positive values in the experiment compared to the control, or less downward motion.\n",
    "\n",
    "- Vertical Profile Maps (dD(per mille), omega, temperature (C), pressure (hPa))\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2288e0-a58e-49d1-a183-19b386ccec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters and Naming \n",
    "model ='Model iCESM and CESM '\n",
    "region = 'PWC Index ' # 'Eastern Pacific ' 'Western Pacific ' \n",
    "variable = 'SLP' #Sea Level Pressure\n",
    "period = \"Post Industrial\"# \"Full LME\" #\"Pre Industrial\",\n",
    "timep = \"_post\"# \"_pre\" # \n",
    "var_name = ['Full', 'GHG', 'LULC','OZA']#, 'ANTHRO']\n",
    "timep_title = \"Post Industrial\"#'Pre Industrial' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55acdd08-5b78-41fa-adfd-aefb773cfd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index Box Parameters \n",
    "## Make geom for E and W PWC index boxes\n",
    "from shapely import geometry\n",
    "from shapely.geometry.polygon import LinearRing, Polygon\n",
    "Elats = [-5, -5, 5, 5]\n",
    "Elons = [90, 150, 150,90]\n",
    "Ering = LinearRing(list(zip(Elons, Elats)))\n",
    "Wlats = [-5, -5, 5, 5]\n",
    "Wlons = [-150,-90,-90,-150]\n",
    "Wring = LinearRing(list(zip(Wlons, Wlats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e577652-fbcf-4e9b-a427-cbfba6709d37",
   "metadata": {},
   "source": [
    "# Read in Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbbb20a-b42f-4b34-8bc5-ae3339b35a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b57fe4d-607a-47d8-aac2-ef26c2f869e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/glade/u/home/calipfleger/stats/PWC_Paper/pwc_clean'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39488f12-00c9-43aa-8314-1fad9c1e35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir_atm = '/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/'\n",
    "file_prefix= '.cam.h0.' \n",
    "i_model = '/b.ie12.B1850C5CN.f19_g16.LME.' ## read in 2&3 iLME Ensembles \n",
    "i_model1 = '/b.ie12.B1850CN.f19_g16.' ## read in iLME ens 1\n",
    "model = '/b.e11.BLMTRC5CN.f19_g16.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb48652-e543-4392-a91f-0d28de7dcc05",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd227382-ef11-4508-a46f-1f9689f9a1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pprint import pprint\n",
    "#import nctoolkit\n",
    "# colors for lines (color blind friendly colors: https://gist.github.com/thriveth/8560036)\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "import matplotlib as mpl  # # Plotting\n",
    "import matplotlib.pyplot as plt  # python plotting package\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from colorspacious import cspace_converter\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "cmaps = OrderedDict()\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LATITUDE_FORMATTER, LONGITUDE_FORMATTER\n",
    "from cartopy.mpl.ticker import LatitudeFormatter, LongitudeFormatter\n",
    "from colorspacious import cspace_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1e0f6f-4aab-4f3b-8439-a1cf3c70a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cftime\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "from scipy import stats\n",
    "from netCDF4 import Dataset as nc\n",
    "from netCDF4 import num2date\n",
    "import netCDF4\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt #python plotting package\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as mcolors\n",
    "from colorspacious import cspace_converter\n",
    "from collections import OrderedDict\n",
    "cmaps = OrderedDict()\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "#import nctoolkit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.feature as cpf\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from shapely import geometry\n",
    "from collections import namedtuple\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107bf4d-ff46-4908-8364-101155642081",
   "metadata": {},
   "source": [
    "# Calculations and Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1284a371-3256-4676-a89f-1012b2d0cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CESM converting month 01 to January \n",
    "from itertools import product\n",
    "from cftime import DatetimeNoLeap\n",
    "year = np.linspace(0,1872, 1872) \n",
    "dates = [DatetimeNoLeap(year, month, 1) for year, month in product(range(1850, 2006), range(1, 13))]\n",
    "da = xr.DataArray(np.arange(1872), coords=[dates], dims=['time'], name='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c422e8b-58c5-41b7-b040-e4b0399f5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set control year \n",
    "i_cntlyear = np.linspace(0,2400, 2400) \n",
    "i_cntldates = [DatetimeNoLeap(i_cntlyear, month, 1) for i_cntlyear, month in product(range(650, 850), range(1, 13))]\n",
    "i_cntlda =xr.DataArray(np.arange(2400), coords=[i_cntldates], dims=['time'], name='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "018a0827-8630-4f46-b100-02bae234cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grid cell weighting to acount for grid cells in extratropics \n",
    "def weights(w):\n",
    "    coslat = np.cos(np.deg2rad(w.lat)) #  Take the cosine of latitude (first converting to radians)\n",
    "    weight_factor = coslat / coslat.mean(dim='lat')#  And divide by its mean value\n",
    "    computed_weight = w * weight_factor # .mean(dim=('time', 'lon', 'lat'))\n",
    "    return computed_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "784be969-55ce-4660-92e9-83d4113178ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Ensemble average \n",
    "def ensav(e):\n",
    "    ens_avg = e.mean(dim = 'ensemble')\n",
    "    return ens_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b4f4988-d311-42f0-954e-52d925d8de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Dr. Samantha Stevenson UCSB\n",
    "#mask_lon = (mytos.lon >= regbox[2]) & (mytos.lon <= regbox[3])\n",
    "#mask_lat = (mytos.lat >= regbox[0]) & (mytos.lat <= regbox[1])\n",
    "#hsst=mytos.where(mask_lon & mask_lat, drop=True).squeeze().isel(lev=23).isel(lev=23).isel(lev=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15f4b275-a161-4c87-a35b-096d064a752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWC Index\n",
    "def compute_index(c):\n",
    "    east = c.sel(lat=slice(-5,5), lon=slice(210,270))\n",
    "    west = c.sel(lat=slice(-5,5), lon=slice(90,150))\n",
    "    #east = c.sel(lat=slice(-10,10), lon=slice(190,250))\n",
    "    #west = c.sel(lat=slice(-10,10), lon=slice(90,150))\n",
    "    avg_east = east.mean(('lat', 'lon'))\n",
    "    avg_west =  west.mean(('lat', 'lon'))\n",
    "    clim_index = (avg_east- avg_west).compute()\n",
    "    return clim_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0df8a96-c581-4210-b24b-3837395a7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for meridional mean and lat lon range \n",
    "def mer(m):\n",
    "    #m_we = weights(m)\n",
    "    mer_lat= m.sel(lat=slice(-20, 20)).mean(dim='lat')\n",
    "    mer_lon = mer_lat.sel(lon=slice(110, 270))\n",
    "    mer_clim = clim(mer_lon)\n",
    "    mer_time = mer_clim.mean(dim='time')\n",
    "    mer_avg = mer_time#.mean(dim = 'ensemble')\n",
    "    return mer_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d485c31-355b-41c0-b400-4eab3b7d98fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Anomaly relative to Climatology for variable \n",
    "def clim(tc): \n",
    "    #units = tc/100 #convert d18O \n",
    "    #convert precip 1000*24*3600\n",
    "    c = tc.assign_coords({'time':(da.time)}) #convert time dimestion to have 01 be january \n",
    "    clim_var = c.groupby('time.month').mean('time') #calculate monthly climatology\n",
    "    clim_anom = c.groupby('time.month') - clim_var # calculate the anomaly relative to the climatology \n",
    "    #anom_weights = weights(clim_anom) #weight functino to account for lat grid size \n",
    "    return  clim_anom #return the anomaly calcuated by the anomaly with time and lat conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7198985-f02f-4fe3-b794-1d561ea01780",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Anomaly relative to Climatology for variable \n",
    "def clim_cntl(tc): \n",
    "    #units = tc/100 #convert d18O \n",
    "    #convert precip 1000*24*3600\n",
    "    c = tc.assign_coords({'time':(i_cntlda.time)}) #convert time dimestion to have 01 be january \n",
    "    clim_var = c.groupby('time.month').mean('time') #calculate monthly climatology\n",
    "    clim_anom = c.groupby('time.month') - clim_var # calculate the anomaly relative to the climatology \n",
    "    #anom_weights = weights(clim_anom) #weight functino to account for lat grid size \n",
    "    return clim_anom #return the anomaly calcuated by the anomaly with time and lat conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e8754a-9d42-4cbb-99fa-1a87baac1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Ensemble average \n",
    "def clim_avg(ca):\n",
    "    #convert precip 1000*24*3600\n",
    "    c = ca.assign_coords({'time':(da.time)})\n",
    "    time_avg = c.mean('time')\n",
    "    ens_avg = time_avg.mean(dim = 'ensemble')\n",
    "    return ens_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acb33cb9-525e-4f7e-a87b-ea5f837be920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Correlation Coefficent using xr.corr \n",
    "def cor(g,t):\n",
    "    ds= []\n",
    "    fcor =xr.corr(g,t, dim = 'time') # g is the global data set and t is the time series index \n",
    "    ds.append(fcor) # add correlation coeefiecent to dataset \n",
    "    cords= xr.concat(ds, dim='ensemble')  # create ensmenble dimesion for correlation coeeficent \n",
    "    cor_avg = cords.mean('ensemble') # calculate ensemble average for correlation coeeficent \n",
    "    return cor_avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31738d25-da2e-44e8-9308-67cbced61f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_trend(var,lon,lat,time,sig):\n",
    "    nlon=len(lon)\n",
    "    nlat=len(lat)\n",
    "    nt=len(time)\n",
    "    vart=zeros(nlat*nlon)\n",
    "    varp=zeros(nlat*nlon)\n",
    "    if len(var.shape)== 3:        \n",
    "        var1=reshape(var,(nt,nlat*nlon)) \n",
    "        for i in range(nlat*nlon):\n",
    "            v=var1[:,i]  \n",
    "            vart[i], intercept, r_value, varp[i], std_err=stats.linregress(time,v) # slope, intercept, r, p, std_error\n",
    "        vart=reshape(vart,(nlat,nlon))\n",
    "        varp=reshape(varp,(nlat,nlon))  \n",
    "        vt.append(vart)\n",
    "        vp.append(varp)\n",
    "        slope = np.stack(vt, axis=0)#, dim='ensemble')\n",
    "        pvalue = np.stack(vp, axis=0)#, dim='ensemble')\n",
    "        sig_pval = ma.masked_greater(pvalue, sig)\n",
    "        pval_avg = avg(sig_pval)\n",
    "        slope_avg = avg(slope)\n",
    "        return (slope, sig_pval, slope_avg, pval_avg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d354ab3-a03d-4aee-9154-dd76dd50d908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Files: /b.e11.BLMTRC5CN.f19_g16.Post Industrial PWC Index \n"
     ]
    }
   ],
   "source": [
    "print('Index Files: ' +  model + period ,''+ region )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de077c-c0e6-419f-a995-63e0c48ae01f",
   "metadata": {},
   "source": [
    "# Read in Index Files: PSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b7ea605-23b3-4d1a-81a1-d62ba557c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'U' #set output variable name for reading in file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "062e9772-8eae-4a0e-a1d4-44a0293ade4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.72s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.54it/s]\n",
      "100%|██████████| 9/9 [00:18<00:00,  2.07s/it]\n",
      "100%|██████████| 4/4 [00:14<00:00,  3.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 6.39 s, total: 2min 51s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    " #set output variable name for reading in file %%time\n",
    "ens = '' #Full forcing ensemble \n",
    "file_suffix= '.185001-200512.nc'\n",
    "ds = []# initialise array:\n",
    "for member in tqdm(range(1,2)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "    \n",
    "for member in tqdm(range(2,3+1)): #loop to read in the 1-9 ensemble members \n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix # set file path \n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens +'00' +file).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "\n",
    "for member in tqdm(range(1,9+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "    \n",
    "for member in tqdm(range(10,13+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ model+ens +'0'+file).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "    \n",
    "var_fullU = xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)})#create ensemble dimension after reading in all the ensemble members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5465e997-2545-46d6-8149-47d3ad209cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'U'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "File \u001b[0;32m/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/core/common.py:280\u001b[0m, in \u001b[0;36mAttrAccessMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[1;32m    279\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m source[name]\n\u001b[0;32m--> 280\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'U'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ens = 'GHG.'  # GHG ensemble \n",
    "file_suffix= '.185001-200512.nc'\n",
    "ds = [] # initialise array:\n",
    "for member in tqdm(range(1,2)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "for member in tqdm(range(3,4+1)): #add in 4th ensmble when permission is not denied \n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "for member in tqdm(range(1,3+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ model +ens +'00' +file).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "var_ghgU = xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89d16dc0-1a28-4eca-8ea6-c4f4cade6241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 3.61 s, total: 1min 48s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ens = 'O3AER.'\n",
    "file_suffix= '.185001-200512.nc'\n",
    "ds = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "\n",
    "ens = 'OZONE_AER.'\n",
    "for member in tqdm(range(1,5+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "\n",
    "var_ozaU = xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "718ecdb8-596e-4efa-bef2-ad2665979b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'U'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "File \u001b[0;32m/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/core/common.py:280\u001b[0m, in \u001b[0;36mAttrAccessMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[1;32m    279\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m source[name]\n\u001b[0;32m--> 280\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'U'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ens = 'LULC.'  #Lulc ensemble \n",
    "file_suffix= '.169001-200512.nc'\n",
    "ds = []\n",
    "for member in tqdm(range(1,3+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(time = slice('1850-02-01', '2006-01-01')).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "ens = 'LULC_HurttPongratz.'\n",
    "file_suffix= '.185001-200512.nc'\n",
    "for member in tqdm(range(1,3+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ model+ ens + '00'+file).sel(time = slice('1850-02-01', '2006-01-01')).sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "var_lulcU = xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63d81d83-dd67-46b4-ba87-79c9b439bd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.97s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.96it/s]\n",
      "100%|██████████| 9/9 [00:40<00:00,  4.55s/it]\n",
      "100%|██████████| 4/4 [00:23<00:00,  5.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 7s, sys: 7.12 s, total: 3min 15s\n",
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "var = 'V' #set output variable name for reading in file %%time\n",
    "ens = '' #Full forcing ensemble \n",
    "file_suffix= '.185001-200512.nc'\n",
    "ds = []# initialise array:\n",
    "for member in tqdm(range(1,2)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "    \n",
    "for member in tqdm(range(2,3+1)): #loop to read in the 1-9 ensemble members \n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix # set file path \n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens +'00' +file).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "\n",
    "for member in tqdm(range(1,9+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "    \n",
    "for member in tqdm(range(10,13+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ model+ens +'0'+file).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "    \n",
    "var_full= xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6293ec2d-d12c-4834-b866-e9bcab4c8431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.65s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.45it/s]\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 s, sys: 904 ms, total: 25.8 s\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ens = 'GHG.'  # GHG ensemble \n",
    "file_suffix= '.185001-200512.nc'\n",
    "ds = [] # initialise array:\n",
    "for member in tqdm(range(1,2)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "for member in tqdm(range(3,4+1)): #add in 4th ensmble when permission is not denied \n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "for member in tqdm(range(1,3+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ model +ens +'00' +file).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "var_ghg = xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fe5b3d5-f38d-45bf-a34d-f465b38807e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 4.08 s, total: 1min 49s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ens = 'O3AER.'\n",
    "file_suffix= '.185001-200512.nc'\n",
    "ds = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "\n",
    "ens = 'OZONE_AER.'\n",
    "for member in tqdm(range(1,5+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "\n",
    "var_oza= xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c5492f5-9962-4147-926a-2287b47099f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  8.63it/s]\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 2.41 s, total: 1min 14s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ens = 'LULC.'  #Lulc ensemble \n",
    "file_suffix= '.169001-200512.nc'\n",
    "ds = []\n",
    "for member in tqdm(range(1,3+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(time = slice('1850-02-01', '2006-01-01')).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "ens = 'LULC_HurttPongratz.'\n",
    "file_suffix= '.185001-200512.nc'\n",
    "for member in tqdm(range(1,3+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ model+ ens + '00'+file).sel(time = slice('1850-02-01', '2006-01-01')).sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)\n",
    "    ds.append(member)\n",
    "var_lulc = xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8758b70-e776-4fd8-99c2-a732eb1bb7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "icntl_indexU = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/U/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.U.065001-084912.nc').sel(lat=slice(-35,35),lon=slice(75,290)).U.squeeze().isel(lev=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4995e4d1-84c9-4031-94b1-ec71f332a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "icntl_indexV = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/V/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.V.065001-084912.nc').sel(lat=slice(-35,35),lon=slice(75,290)).V.squeeze().isel(lev=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080b054-b8c1-412e-8cff-3b55b360aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'V'\n",
    "var_full.to_netcdf(variable+'full.nc')\n",
    "var_ghg.to_netcdf(variable+'ghg.nc')\n",
    "var_oza.to_netcdf(variable+'oza.nc')\n",
    "var_lulc.to_netcdf(variable+'lulc.nc')\n",
    "icntl_indexV.to_netcdf(variable+'cntlV.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16281065-bf94-4402-82ec-2d957fbdd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'U'\n",
    "var_fullU.to_netcdf(variable+'full.nc')\n",
    "var_ghgU.to_netcdf(variable+'ghg.nc')\n",
    "var_ozaU.to_netcdf(variable+'oza.nc')\n",
    "var_lulcU.to_netcdf(variable+'lulc.nc')\n",
    "icntl_indexU.to_netcdf(variable+'cntlU.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d260ff-8766-49f1-bd4e-753ab6df0ca2",
   "metadata": {},
   "source": [
    "# Read in Second Variable: dD Files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e7cf3-2055-4127-b453-e90ec7c5ba7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate dD for full forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a134d7-92eb-448c-b37e-19c7219fa11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ens = ''\n",
    "file_suffix= '.185001-200512.nc'\n",
    "\n",
    "var = 'H218Or'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H218Or = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H218OL'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H218OL = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H218OS'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H218OS = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H218OR'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H218OR = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H218Os'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H218Os = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H218OV'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H218OV = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H218OI'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H218OI = xr.concat(dsf, dim='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5e627-d577-4040-96e0-3702e4d7ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_H218O = post_H218Or + post_H218OR +post_H218Os +post_H218OS + post_H218OI + post_H218OL +post_H218OV # adll all 18O componen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5489b-a03c-4561-8aa2-42e0933c58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del post_H218Or \n",
    "del post_H218OR \n",
    "del post_H218Os \n",
    "del post_H218OS \n",
    "del post_H218OI \n",
    "del post_H218OL\n",
    "del post_H218OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b929161-c292-4825-8c28-ea58aa986633",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ens = ''\n",
    "file_suffix= '.185001-200512.nc'\n",
    "\n",
    "var = 'H216Or'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H216Or = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H216OL'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H216OL = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H216OS'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H216OS = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H216OR'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H216OR = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H216Os'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H216Os = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H216OV'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H216OV = xr.concat(dsf, dim='ensemble')\n",
    "\n",
    "var = 'H216OI'\n",
    "dsf = []# initialise array:\n",
    "for member in range(1,2):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)   \n",
    "for member in range(2,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsf.append(member)     \n",
    "post_H216OI = xr.concat(dsf, dim='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff5cc7-88e0-4ced-9fbe-ab306bdee841",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_H216O= post_H216Or + post_H216OR +post_H216Os +post_H216OS + post_H216OI + post_H216OL + post_H216OV # add all 16O componets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377eb721-f0ee-4b90-87db-d6b858d78154",
   "metadata": {},
   "outputs": [],
   "source": [
    "del post_H216Or\n",
    "del post_H216OR \n",
    "del post_H216Os \n",
    "del post_H216OS \n",
    "del post_H216OI \n",
    "del post_H216OL \n",
    "del post_H216OV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc48d7-a890-4d83-9450-53c47b2f2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_full =  (((post_H218O/post_H216O)-1)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de891a69-b560-4e51-b2f3-69675ead58eb",
   "metadata": {},
   "source": [
    "## Read in GHG files and Calculate dD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dca5df-1ec3-4a6f-ba08-93f7e40e611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "## GHG\n",
    "ens = 'GHG.'  #set ensemble \n",
    "\n",
    "var = 'H218OL'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H218OL_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H218Or'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H218Or_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H218OS'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H218OS_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H218OR'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H218OR_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H218Os'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H218Os_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H218OV'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H218OV_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H218OI'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H218OI_ghg = xr.concat(dsg, dim='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09080d74-2f09-43e8-a6b1-93b691689cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "post_H218O_ghg = post_H218Or_ghg + post_H218OR_ghg +post_H218Os_ghg +post_H218OS_ghg + post_H218OI_ghg + post_H218OL_ghg +post_H218OV_ghg # adll all 18O componen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d7dd7-73ba-404e-b09a-b524536755ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "del post_H218Or_ghg \n",
    "del post_H218OR_ghg \n",
    "del post_H218Os_ghg  \n",
    "del post_H218OS_ghg  \n",
    "del post_H218OI_ghg  \n",
    "del post_H218OL_ghg \n",
    "del post_H218OV_ghg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ba30c-2d35-4667-9326-9f4ec696136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## GHG\n",
    "var = 'H216OL'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H216OL_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H216Or'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H216Or_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H216OS'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H216OS_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H216OR'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H216OR_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H216Os'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H216Os_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H216OV'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H216OV_ghg = xr.concat(dsg, dim='ensemble')\n",
    "\n",
    "var = 'H216OI'\n",
    "dsg = []\n",
    "for member in (1,3,4):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsg.append(member)\n",
    "post_H216OI_ghg = xr.concat(dsg, dim='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceea734-ae01-4c42-ad86-42220908d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "post_H216O_ghg = post_H216Or_ghg + post_H216OR_ghg +post_H216Os_ghg +post_H216OS_ghg + post_H216OI_ghg + post_H216OL_ghg +post_H216OV_ghg # add all 16O componets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a85e0-3c46-430f-af1a-4a7783655dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "del post_H216Or_ghg # rC is convective rain \n",
    "del post_H216OR_ghg # L - large scale \n",
    "del post_H216Os_ghg #SC = snow rates convective?\n",
    "del post_H216OS_ghg # SL = snow rates large scale?\n",
    "del post_H216OI_ghg #ice \n",
    "del post_H216OL_ghg #liquid \n",
    "del post_H216OV_ghg #vapor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c54e8-81c1-4127-b56f-6d0c4297e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "var_ghg =  (((post_H218O_ghg/post_H216O_ghg)-1)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d485340-d299-423d-b723-e888fbaaf089",
   "metadata": {},
   "source": [
    "## Read in OZA files and Calculate dD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf6cbf-2974-4492-98b0-13b8630fe3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# OZA\n",
    "ens = 'O3AER.'\n",
    "var = 'H218Or'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H218Or_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H218OL'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H218OL_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H218OS'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H218OS_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H218OR'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H218OR_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H218Os'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H218Os_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H218OV'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H218OV_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H218OI'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H218OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H218OI_oza = xr.concat(dso, dim='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d8789e-1e1c-4114-9e37-53db70564192",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "post_H218O_oza = post_H218Or_oza + post_H218OR_oza +post_H218Os_oza +post_H218OS_oza+ post_H218OI_oza + post_H218OL_oza+post_H218OV_oza # adll all 18O componen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e4f34-f020-42fc-aae5-a1e1e209bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del post_H218Or_oza \n",
    "del post_H218OR_oza \n",
    "del post_H218Os_oza  \n",
    "del post_H218OS_oza  \n",
    "del post_H218OI_oza  \n",
    "del post_H218OL_oza \n",
    "del post_H218OV_oza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b198321-6f84-4ba9-a7e8-3dea20f67cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# OZA\n",
    "var = 'H216Or'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H216Or_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H216OL'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H216OL_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H216OS'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H216OS_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H216OR'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H216OR_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H216Os'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H216Os_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H216OV'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H216OV_oza = xr.concat(dso, dim='ensemble')\n",
    "\n",
    "var = 'H216OI'\n",
    "dso = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290)).H216OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dso.append(member)   \n",
    "post_H216OI_oza = xr.concat(dso, dim='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a7f46-8d1d-4d8d-a085-8cda72f784ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "H216O_oza = post_H216Or_oza + post_H216OR_oza +post_H216Os_oza +post_H216OS_oza +post_H216OI_oza + post_H216OL_oza +post_H216OV_oza # add all 16O componets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527897a-d4c7-4cbe-89a8-2d655a572caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del post_H216Or_oza # rC is convective rain \n",
    "del post_H216OR_oza # L - large scale \n",
    "del post_H216Os_oza #SC = snow rates convective?\n",
    "del post_H216OS_oza # SL = snow rates large scale?\n",
    "del post_H216OI_oza #ice \n",
    "del post_H216OL_oza #liquid \n",
    "del post_H216OV_oza #vapor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5559c8-dd15-4c6f-9886-3619d9ff2225",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "var_oza =  (((post_H218O_oza/H216O_oza)-1)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f35865-fb20-422d-a1f2-65ddc9b031ab",
   "metadata": {},
   "source": [
    "## Read in LULC files and Calculate dD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb21966-6651-43e4-a738-899ae4fd6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ens = 'LULC.'  #Lulc ensemble  \n",
    "file_suffix= '.169001-200512.nc'\n",
    "\n",
    "var = 'H218OI'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H218OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H218OI_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "\n",
    "var = 'H218Or'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H218Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H218Or_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "var = 'H218OS'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H218OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H218OS_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "var = 'H218OR' \n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H218OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H218OR_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "\n",
    "var = 'H218Os'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H218Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H218Os_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "var = 'H218OV'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H218OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H218OV_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "var = 'H218OL'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H218OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H218OL_lulc = xr.concat(dsl, dim='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b0b84-f572-46b5-80cd-c81a6bbd8d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "post_H218O_lulc = post_H218Or_lulc + post_H218OR_lulc +post_H218Os_lulc +post_H218OS_lulc+ post_H218OI_lulc + post_H218OL_lulc+post_H218OV_lulc # adll all 18O componen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f45efd-df33-43c8-9960-61d6fde20495",
   "metadata": {},
   "outputs": [],
   "source": [
    "del post_H218Or_lulc \n",
    "del post_H218OR_lulc \n",
    "del post_H218Os_lulc  \n",
    "del post_H218OS_lulc  \n",
    "del post_H218OI_lulc  \n",
    "del post_H218OL_lulc \n",
    "del post_H218OV_lulc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee672bca-643e-486b-9fa5-6ade4587d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'H216OI'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H216OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H216OI_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "\n",
    "var = 'H216Or'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H216Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H216Or_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "var = 'H216OS'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H216OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H216OS_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "var = 'H216OR' \n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H216OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H216OR_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "\n",
    "var = 'H216Os'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H216Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H216Os_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "var = 'H216OV'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H216OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H216OV_lulc = xr.concat(dsl, dim='ensemble')\n",
    "\n",
    "var = 'H216OL'\n",
    "dsl = []\n",
    "for member in range(1,3+1):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-30,30),lon=slice(75,290), time = slice('1850-02-01', '2006-01-01')).H216OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "    dsl.append(member)\n",
    "post_H216OL_lulc = xr.concat(dsl, dim='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcacc602-fc66-4d08-805e-fd51c2ca5961",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "post_H216O_lulc = post_H216Or_lulc + post_H216OR_lulc +post_H216Os_lulc +post_H216OS_lulc+ post_H216OI_lulc + post_H216OL_lulc+post_H216OV_lulc # adll all 16O componen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8087009-71ea-4e9b-ba87-eeafa9c127fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del post_H216Or_lulc \n",
    "del post_H216OR_lulc \n",
    "del post_H216Os_lulc  \n",
    "del post_H216OS_lulc  \n",
    "del post_H216OI_lulc  \n",
    "del post_H216OL_lulc \n",
    "del post_H216OV_lulc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083ee93-5b1c-49e9-96bb-960fcfe54544",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "var_lulc =  (((post_H218O_lulc/post_H216O_lulc)-1)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceaf4d8-3f3b-42cf-90d9-fd1a3b46c5ef",
   "metadata": {},
   "source": [
    "## Read in Control files and Calculate dD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce58b82-5b8a-42b6-8e34-6754a77e836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Control \n",
    "##cntl_PREC_H218O = cntl_PRECRC_H218Or + cntl_PRECRL_H218OR +cntl_PRECSC_H218Os +cntl_PRECSL_H218OS\n",
    "#cntl_PREC_H216O = cntl_PRECRC_H216Or + cntl_PRECRL_H216OR +cntl_PRECSC_H216Os +cntl_PRECSL_H216OS\n",
    "#cntl_var = (((cntl_PREC_H218O/cntl_PREC_H216O)-1)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df84b90-9bc5-4c02-b012-cd14263fa315",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dH Control \n",
    "cntl_H218Or = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H218Or/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H218Or.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H218Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23) #AttributeError: 'CFTimeIndex' object has no attribute '_cache'\n",
    "cntl_H216Or = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H216Or/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H216Or.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H216Or.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "\n",
    "cntl_H218OR = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H218OR/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H218OR.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H218OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23) #AttributeError: 'CFTimeIndex' object has no attribute '_cache'\n",
    "cntl_H216OR = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H216OR/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H216OR.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H216OR.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "\n",
    "cntl_H218Os = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H218Os/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H218Os.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H218Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23) #AttributeError: 'CFTimeIndex' object has no attribute '_cache'\n",
    "cntl_H216Os = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H216Os/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H216Os.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H216Os.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "\n",
    "cntl_H218OS = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H218OS/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H218OS.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H218OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23) #AttributeError: 'CFTimeIndex' object has no attribute '_cache'\n",
    "cntl_H216OS = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H216OS/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H216OS.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H216OS.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "\n",
    "cntl_H218OI = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H218OI/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H218OI.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H218OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23) #AttributeError: 'CFTimeIndex' object has no attribute '_cache'\n",
    "cntl_H216OI = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H216OI/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H216OI.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H216OI.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "\n",
    "cntl_H218OL = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H218OL/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H218OL.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H218OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23) #AttributeError: 'CFTimeIndex' object has no attribute '_cache'\n",
    "cntl_H216OL = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H216OL/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H216OL.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H216OL.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)\n",
    "\n",
    "cntl_H218OV = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H218OV/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H218OV.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H218OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23) #AttributeError: 'CFTimeIndex' object has no attribute '_cache'\n",
    "cntl_H216OV = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/H216OV/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.H216OV.065001-084912.nc').sel(lat=slice(-30,30),lon=slice(75,290)).H216OV.squeeze().isel(lev=23).isel(lev=23).isel(lev=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6224b1-769d-45d5-aabf-c643a9da88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Control \n",
    "cntl_H218O = cntl_H218Or + cntl_H218OR +cntl_H218Os +cntl_H218OS +cntl_H218OI +cntl_H218OL +cntl_H218OV\n",
    "cntl_H216O = cntl_H216Or + cntl_H216OR +cntl_H216Os +cntl_H216OS +cntl_H216OI +cntl_H216OL +cntl_H216OV\n",
    "var_cntl = (((cntl_H218O/cntl_H216O)-1)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c1e9c-979f-4231-97f7-96b8e36bf17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del cntl_H218Or \n",
    "del cntl_H216Or \n",
    "del cntl_H218OR \n",
    "del cntl_H216OR \n",
    "del cntl_H218Os \n",
    "del cntl_H216Os \n",
    "del cntl_H218OS\n",
    "del cntl_H216OS \n",
    "del cntl_H218OI \n",
    "del cntl_H216OI \n",
    "del cntl_H218OL\n",
    "del cntl_H216OL \n",
    "del cntl_H218OV \n",
    "del cntl_H216OV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e45cf7-7fc2-41dc-a683-2f4bb2b96253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slp_index(r):\n",
    "    r_lat= r.sel(lat=slice(-5, 5)).mean(dim='lat')\n",
    "    r_mer =  r_lat.sel(lon=slice(110, 270))\n",
    "    return r_mer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd9dbf-0608-46d1-87e2-38c9916bd752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_mer(r):\n",
    "    r_lat= r.sel(lat=slice(-5, 5)).mean(dim='lat')\n",
    "    r_mer =  r_lat.sel(lon=slice(110, 270))\n",
    "    r_mer18 = r_mer.isel(lev = 18)\n",
    "    return r_mer, r_mer18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96811603-d1a4-46f7-9734-1390131a5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Anomaly relative to Climatology for variable \n",
    "def clim_anom(v, p): \n",
    "    units = v/100 #convert to hPa d18O #convert precip 1000*24*3600\n",
    "    units_p = p/100 #convert to hPa d18O #convert precip 1000*24*3600\n",
    "   \n",
    "    pi = units_p.assign_coords({'time':(i_cntlda.time)}) #convert time dimestion to have 01 be january \n",
    "    vv = units.assign_coords({'time':(da.time)}) #convert time dimestion to have 01 be january \n",
    "\n",
    "    del units_p\n",
    "    del units\n",
    "\n",
    "    # Group by month dimension\n",
    "    pi_month =pi.groupby('time.month').mean('time') #calculate monthly climatology\n",
    "    clim_month = vv.groupby('time.month').mean('time') #calculate monthly climatology #return\n",
    "\n",
    "    # Calcualte anomaly relative to climatology \n",
    "    pi_anom = pi.groupby('time.month') - pi_month # 1 calculate the anomaly relative to the climatology x4\n",
    "    clim_anom = vv.groupby('time.month') - clim_month #2 calculate the anomaly relative to the climatology x4\n",
    "    \n",
    "    del pi_month\n",
    "    del clim_month \n",
    "\n",
    "    # Ensemble average effect of forcing \n",
    "    eforcing_avg = (vv - pi).mean(dim = 'ensemble') # 3netcdf x4\n",
    "    # Meridtrional Average \n",
    "    clim_mer, clim_mer18 = reg_mer(vv) # x4\n",
    "    pi_mer, pi_mer18 = reg_mer(pi) #x1\n",
    "\n",
    "    #del vv\n",
    "    #del pi \n",
    "    # Ensemble averagefor climatigy realtive to anomaly and effect of forcing anomalies \n",
    "    anom_eforcing_avg = (clim_anom - pi_anom).mean(dim = 'ensemble') #4 return  #netcdfx4\n",
    "    clim_anomavg = clim_anom.mean(dim = 'ensemble')  #5 return x4\n",
    "    \n",
    "    # Vertical Slice \n",
    "    clim_anom_mer, clim_anom_mer18 = reg_mer(clim_anom) #6, 7 x4\n",
    "    pi_anom_mer, pi_anom_mer18 = reg_mer(pi_anom) #8, 9 x1\n",
    "    \n",
    "    # all levels  tropical domain  effect of forcing climatology and climatology anomaly \n",
    "    eforcing_mer = (clim_mer - pi_mer).mean(dim = 'ensemble') # 10 return x4\n",
    "    anom_eforcing_mer = (clim_anom_mer - pi_anom_mer).mean(dim = 'ensemble') # 11 return x4\n",
    "\n",
    "    del clim_mer\n",
    "    del pi_mer\n",
    "\n",
    "    # level 18 effect of forcing climatology and climatology anomaly \n",
    "    \n",
    "    eforcing_mer18 = (clim_mer18 - pi_mer18).mean(dim = 'ensemble') #12 return x4\n",
    "    anom_eforcing_mer18 = (clim_anom_mer18 - pi_anom_mer18).mean(dim = 'ensemble') # 13 return x4\n",
    "\n",
    "  \n",
    "    return vv, pi, clim_anom, pi_anom, eforcing_avg, anom_eforcing_avg,clim_anomavg, anom_eforcing_mer, eforcing_mer, anom_eforcing_mer,anom_eforcing_mer18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43380899-0607-4c25-868e-d18b2dfc93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for meridional mean and lat lon range \n",
    "def mer_series(m):\n",
    "    #m_we = weights(m)\n",
    "    c = m.assign_coords({'time':(da.time)}) #convert time dimestion to have 01 be january \n",
    "    mer_lat= c.sel(lat=slice(-20, 20)).mean(dim='lat')\n",
    "    mer_lon = mer_lat.sel(lon=slice(110, 270)).mean(dim='lon')\n",
    "    #mer_clim = clim(mer_lon)\n",
    "    mer_time = mer_lon.mean(dim='time')\n",
    "    mer_avg = mer_time.mean(dim = 'ensemble')\n",
    "    mer_series = mer_avg.to_series()\n",
    "    return mer_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad8cde2-a337-4d63-93b5-c625a81def12",
   "metadata": {},
   "source": [
    "# Select Atmospheric Pressure Level (524 hpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472dc79f-1d51-473d-9bf7-9ddf29342119",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ghg18 = var_ghg.isel(lev = 18)\n",
    "var_full18 = var_full.isel(lev = 18)\n",
    "var_oza18 = var_oza.isel(lev = 18)\n",
    "var_lulc18 = var_full.isel(lev = 18)\n",
    "var_cntl18 = var_cntl.isel(lev = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe5dee-d2c8-48da-b152-63b0208f5080",
   "metadata": {},
   "source": [
    "# Calculate Climatology \n",
    "- Convert CESM data to start at 1 January, not python index\n",
    "- Weight by grid cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4301796-8cfa-4f9f-87d9-5462fdf004cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate anomaly relative to climatology for global variable forcing files \n",
    "anom_var18 = clim(var_full18)#var_full.isel(lev = 18))\n",
    "anom_var_ghg18 = clim(var_ghg18)\n",
    "anom_var_lulc = clim(var_lulc)\n",
    "anom_var_oza18 = clim(var_oza18)\n",
    "anom_var_cntl18 = clim_cntl(var_cntl18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991cda9-978a-4233-aefa-29ed3af0b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate anomaly relative to climatology for global variable forcing files \n",
    "anom_var = clim(var_full)#var_full.isel(lev = 18))\n",
    "anom_var_ghg = clim(var_ghg)\n",
    "#anom_var_lulc = clim(var_lulc)\n",
    "anom_var_oza = clim(var_oza)\n",
    "anom_var_cntl = clim_cntl(var_cntl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62254ff6-7b35-4621-b282-e5d06eed026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate anomaly relative to climatology for index forcing files \n",
    "anom_index = clim(post_index)\n",
    "anom_index_ghg = clim(post_index_ghg)\n",
    "#anom_index_lulc = clim(index_lulc)\n",
    "anom_index_oza = clim(post_index_oza)\n",
    "anom_index_cntl = clim_cntl(icntl_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8837f60-9cfb-44ba-ad13-174f0815519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate anomaly relative to climatology for index forcing files \n",
    "#anom_index_avg = clim(post_index).mean(dim = 'time')\n",
    "#anom_index_ghg_avg  = clim(post_index_ghg).mean(dim = 'time')\n",
    "#anom_index_lulc = clim(index_lulc)\n",
    "#anom_index_oza_avg  = clim(post_index_oza).mean(dim = 'time')\n",
    "#anom_index_cntl_avg  = clim_cntl(icntl_index).mean(dim = 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f22e66-94d8-44b2-bf9b-c797b16ad446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tens (tt):\n",
    "    test = tt.mean(dim = 'time')\n",
    "    test2 = test.mean(dim = 'ensemble')\n",
    "    return test2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4981f-3af1-4629-b985-8cfa6ed69b70",
   "metadata": {},
   "source": [
    "# Calculate ensemble average climatology anomaly s "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c79b810-3a35-48b9-b722-be17e3fac1a4",
   "metadata": {},
   "source": [
    "# Mapping the Climatological Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f49f26-e454-46cc-9cbc-975cfcc52184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anom_var_cntl_avg  = tens(anom_var_cntl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77950a0-6cc5-4041-bcbd-6f2f5aac5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate anomaly relative to climatology for global variable forcing files \n",
    "anom_var_avg18 = tens(anom_var18)#var_full.isel(lev = 18))\n",
    "anom_var_ghg_avg18  = tens(anom_var_ghg18)\n",
    "#anom_var_lulc = clim(var_lulc)\n",
    "anom_var_oza_avg18 = tens(anom_var_oza18)\n",
    "#anom_var_cntl_avg18  = tens(anom_var_cntl18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47156a07-9fce-4e37-94d8-73787a1a1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_maps = [anom_var_avg18,anom_var_ghg_avg18, anom_var_oza_avg18 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe99a7c-e45f-4a90-9322-d757a43c2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate anomaly relative to climatology for global variable forcing files \n",
    "anom_var_avg = tens(anom_var)#var_full.isel(lev = 18))\n",
    "anom_var_ghg_avg  = tens(anom_var_ghg)\n",
    "#anom_var_lulc = clim(var_lulc)\n",
    "anom_var_oza_avg  = tens(anom_var_oza)\n",
    "#anom_var_cntl_avg  = tens(anom_var_cntl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9301878e-da8e-4680-b39d-b0d359b93f3b",
   "metadata": {},
   "source": [
    "# Vertical Slice: Meridional Mean and Vertical Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea17251-b67e-4ba4-a789-c5632f79a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertplot(v):\n",
    "    # Plotting the average of the meridional mean of the vertical velocity and pressure contour lines\n",
    "    ax = fig.add_subplot(2,2,i+1)\n",
    "    contour = v[i].plot.contourf(ax=ax, levels=30, cmap='RdBu_r', vmin= -0.000002, vmax= 0.000002)\n",
    "    pressure_contour = v[i].plot.contour(ax=ax, levels=10, colors='k', linewidths=0.5)\n",
    "    # Add contour line labels with numeric values\n",
    "    ax.clabel(pressure_contour, fmt='%1.2f', colors='k', fontsize=8)\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Pressure (hPa)')\n",
    "    plt.title(var_name[i] + ' Average Meridional Mean dH')\n",
    "    #cbar = plt.colorbar(contour, label='Pa/s')  # Create the colorbar using the contour object\n",
    "    #plt.gca().invert_yaxis()  # Flip the y-axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14a7cb-fa21-4b26-857f-d35703eb7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trop_plot(p):\n",
    "    ax = fig.add_subplot(2,2,i+1, projection=ccrs.Robinson(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    plt.contourf(lon,lat,p[i],cmap='bwr', add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "    plt.pcolor(lon,lat,p[i], cmap='bwr', vmin=-1, vmax=1, transform=ccrs.PlateCarree())  \n",
    "    #calculate significance of trends\n",
    "    sig_p=xr.DataArray(data=p[i].values*np.sqrt((df-2)/(1-np.square(p[i].values))), \n",
    "                       dims=[\"lat\",\"lon'\"], coords=[lat, lon])\n",
    "    sig_p.plot.contourf(ax=ax,levels = [-1*t95, -1*t90, t90, t95], colors='none', \n",
    "                        hatches=['..', None, None, None, '..'], extend='both', add_colorbar=False, \n",
    "                        transform=ccrs.PlateCarree())\n",
    "    ax.set_extent([75, 290, -30, 30], crs=ccrs.PlateCarree())\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = True\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.xlocator = mticker.FixedLocator([-90, -135, 180, 135, 90])\n",
    "    gl.ylocator = mticker.FixedLocator([-20, -10, 0, 10, 20])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.xlabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    gl.ylabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.ylabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    ax.add_geometries([Ering], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth=2.5)\n",
    "    ax.add_geometries([Wring], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth =2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.title(var_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5881e-5779-4d4c-b14f-e153a4ab07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for meridional mean and lat lon range \n",
    "def mer_clim(m):\n",
    "    #m_we = weights(m)\n",
    "    mer_lat= m.sel(lat=slice(-20, 20)).mean(dim='lat')\n",
    "    mer_lon = mer_lat.sel(lon=slice(110, 270))\n",
    "    mer_clim = clim(mer_lon)\n",
    "    mer_time = mer_clim.mean(dim='time')\n",
    "    mer_series= mer_time.mean(dim = 'ensemble')\n",
    "    return mer_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eed386-1ab6-4624-910b-1a9a4ef753ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for meridional mean and lat lon range \n",
    "def mer_clim_cntl(m):\n",
    "    c = m.assign_coords({'time':(i_cntlda.time)}) #convert time dimestion to have 01 be january \n",
    "    mer_lat= c.sel(lat=slice(-20, 20)).mean(dim='lat')\n",
    "    mer_lon = mer_lat.sel(lon=slice(110, 270))\n",
    "    mer_time = mer_lon.mean(dim='time')\n",
    "    return mer_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1009b49-23f1-405f-9d46-705d8a4b76b3",
   "metadata": {},
   "source": [
    "# 524 hPa 20-20 avg over 1850-2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94fd58-7b78-419c-bb75-8090c0fc050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "series = mer_clim(var_full)#var_full.isel(lev = 18))\n",
    "series_ghg  = mer_clim(var_ghg)\n",
    "#anom_var_lulc = clim(var_lulc)\n",
    "series_oza = mer_clim(var_oza)\n",
    "anom_var_cntl_avgmer  = mer_clim_cntl(anom_var_cntl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d9505-74a0-4d5c-89e0-400c01c54aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_avg = [series, series_ghg, series_oza, anom_var_cntl_avgmer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b7bb5-65d3-449e-95ca-882a5404a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trop_plot(p):\n",
    "    ax = fig.add_subplot(2,2,i+1, projection=ccrs.Robinson(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    plt.contourf(lon,lat,p[i],cmap='bwr', add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "    plt.pcolor(lon,lat,p[i], cmap='bwr', vmin=-1, vmax=1, transform=ccrs.PlateCarree())  \n",
    "    #calculate significance of trends\n",
    "    sig_p=xr.DataArray(data=p[i].values*np.sqrt((df-2)/(1-np.square(p[i].values))), \n",
    "                       dims=[\"lat\",\"lon'\"], coords=[lat, lon])\n",
    "    sig_p.plot.contourf(ax=ax,levels = [-1*t95, -1*t90, t90, t95], colors='none', \n",
    "                        hatches=['..', None, None, None, '..'], extend='both', add_colorbar=False, \n",
    "                        transform=ccrs.PlateCarree())\n",
    "    ax.set_extent([75, 290, -30, 30], crs=ccrs.PlateCarree())\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = True\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.xlocator = mticker.FixedLocator([-90, -135, 180, 135, 90])\n",
    "    gl.ylocator = mticker.FixedLocator([-20, -10, 0, 10, 20])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.xlabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    gl.ylabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.ylabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    ax.add_geometries([Ering], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth=2.5)\n",
    "    ax.add_geometries([Wring], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth =2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.title(var_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f5510-05b1-4021-9d94-cf4b7f2a7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "fig.dpi = 600\n",
    "for i in range(len(clim_avg)):\n",
    "    vertplot(clim_avg)\n",
    "plt.suptitle('dD Correlation with ' + region, y =.65)\n",
    "#plt.rcParams['font.size'] = '24'\n",
    "plt.subplots_adjust(hspace=-1, wspace=0)\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "plt.tight_layout()\n",
    "plt.savefig(variable + \"glob_cor_post_anom.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e95ad1-834d-4c76-b314-126e95d94115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for meridional mean and lat lon range \n",
    "def mer_series(m):\n",
    "    #m_we = weights(m)\n",
    "    c = m.assign_coords({'time':(da.time)}) #convert time dimestion to have 01 be january \n",
    "    mer_lat= c.sel(lat=slice(-20, 20)).mean(dim='lat')\n",
    "    mer_lon = mer_lat.sel(lon=slice(110, 270)).mean(dim='lon')\n",
    "    #mer_clim = clim(mer_lon)\n",
    "    mer_time = mer_lon.mean(dim='time')\n",
    "    mer_avg = mer_time.mean(dim = 'ensemble')\n",
    "    mer_series = mer_avg.to_series()\n",
    "    return mer_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26d032-8859-4703-9f93-b8842b026cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for meridional mean and lat lon range \n",
    "def mer_series_cntl(m):\n",
    "    c = m.assign_coords({'time':(i_cntlda.time)}) #convert time dimestion to have 01 be january \n",
    "    mer_lat= c.sel(lat=slice(-20, 20)).mean(dim='lat')\n",
    "    mer_lon = mer_lat.sel(lon=slice(110, 270)).mean(dim='lon')\n",
    "    mer_time = mer_lon.mean(dim='time')\n",
    "    mer_series = mer_time.to_series()\n",
    "    return mer_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a8cf7-f055-4ab2-bdc6-6d4723571645",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate anomaly relative to climatology for global variable forcing files \n",
    "series = mer_series(anom_var)#var_full.isel(lev = 18))\n",
    "series_ghg  = mer_series(anom_var_ghg)\n",
    "#anom_var_lulc = clim(var_lulc)\n",
    "series_oza = mer_series(anom_var_oza)\n",
    "series_cntl = mer_cntl(anom_var_cntl)\n",
    "\n",
    "df = pd.DataFrame({'Full': series, 'GHG': series_ghg, 'OZA': series_oza})\n",
    "df.plot(kind='bar', title ='dDV Anomalies as a function of height in the atmosphere 20N-20S').invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf287824-0a2c-43a4-a3e6-da62999d5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "series_cntl  = mer_cntl(var_cntl)\n",
    "series = mer_series(var_full)#var_full.isel(lev = 18))\n",
    "series_ghg  = mer_series(var_ghg)\n",
    "#anom_var_lulc = clim(var_lulc)\n",
    "series_oza = mer_series(var_oza)\n",
    "\n",
    "df = pd.DataFrame({'Full': series, 'GHG': series_ghg, 'OZA': series_oza})\n",
    "df.plot(kind='bar', title ='dD as a function of height in the atmosphere 20N-20S').invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976bc7c1-4bea-4a57-b9b3-fa992b8e4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "series =series - series_cntl\n",
    "series_ghg =series_ghg - series_cntl\n",
    "series_oza =series_oza - series_cntl\n",
    "\n",
    "df = pd.DataFrame({'Full': series, 'GHG': series_ghg, 'OZA': series_oza})\n",
    "df.plot(kind='bar', title ='dD as a function of height in the atmosphere 20N-20S \\n (Forcing - PI CNTL)').invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37b982-a0e5-48b6-8931-9e1048bcc953",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate PWC index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d28c09-3a29-4845-9464-35ffef41ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "index = compute_index(anom_index)\n",
    "index_ghg = compute_index(anom_index_ghg)\n",
    "#index_lulc = compute_index(anom_index_lulc)\n",
    "index_oza = compute_index(anom_index_oza)\n",
    "index_cntl = compute_index(anom_index_cntl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef44b76-bf8d-4640-beef-a44258ee9cd2",
   "metadata": {},
   "source": [
    "# Calculate Correlation with PWC Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23950f11-045a-4099-9cd9-8e97dd875a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_f = cor(anom_var, index)\n",
    "cor_g = cor(anom_var_ghg, index_ghg)\n",
    "#cor_l = cor(anom_var_lulc, pwc_lulc)\n",
    "cor_o = cor(anom_var_oza, index_oza)\n",
    "cor_var_cntl = cor(anom_var_cntl, index_cntl)\n",
    "cors = [cor_f, cor_g, cor_o, cor_var_cntl]#make list of correlations to loop over "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d14e2-7c75-4a0b-b138-7bbfb5159ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SLP\n",
    "#cor_fin = cor(anom_index, index)\n",
    "#cor_gin= cor(anom_index_ghg, index_ghg)\n",
    "#cor_lin = cor(anom_index_lulc, index_lulc)\n",
    "#cor_oin = cor(anom_index_oza, index_oza)\n",
    "#cor_cin = cor(anom_index_cntl, index_cntl)\n",
    "#icor_PSL = cor(ianom_var_cntl, ipwc_cntl)\n",
    "#corsin= [cor_fin, cor_gin,  cor_oin, cor_cin] #cor_lP,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaca2b3-49bf-4a93-83f1-19e0a26b9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = [cor_var_cntl]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c393001-4406-4ce2-a3f7-94d841c641a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plotting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44877ebf-af86-4922-998c-ca2562be35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = post_index.lat\n",
    "lon = post_index.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d967d1f-3175-4644-8ef0-57dc1b345695",
   "metadata": {},
   "outputs": [],
   "source": [
    "lent = len(cors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = ['Full Forcing', 'GHG','Ozone-Aerosol', 'PI Cntl']#, 'ANTHRO']'LULC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b296ae-b10b-44a9-b0fd-cdd29d97cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 35 #degrees of freedom \n",
    "t90=stats.t.ppf(1-0.05, df-2) # testing for p-value 90% significant \n",
    "t95=stats.t.ppf(1-0.025, df-2) # testing for p-value 95% significant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f3479-298a-46e5-987d-95b77cefe8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertplot(v):\n",
    "    # Plotting the average of the meridional mean of the vertical velocity and pressure contour lines\n",
    "    fig, ax = plt.subplots(figsize=(20, 6))\n",
    "    contour = v.plot.contourf(ax=ax, levels=30, cmap='RdBu_r', vmin= -0.000002, vmax= 0.000002)\n",
    "    pressure_contour = v.plot.contour(ax=ax, levels=10, colors='k', linewidths=0.5)\n",
    "    # Add contour line labels with numeric values\n",
    "    ax.clabel(pressure_contour, fmt='%1.2f', colors='k', fontsize=8)\n",
    "\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Pressure (hPa)')\n",
    "    plt.title(var_name + ' Average Meridional Mean dH')\n",
    "    #cbar = plt.colorbar(contour, label='Pa/s')  # Create the colorbar using the contour object\n",
    "    #plt.gca().invert_yaxis()  # Flip the y-axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33abe8fa-a647-453f-891e-816c6951b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trop_plot(p):\n",
    "    ax = fig.add_subplot(2,2,i+1, projection=ccrs.Robinson(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    plt.contourf(lon,lat,p[i],cmap='bwr', add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "    plt.pcolor(lon,lat,p[i], cmap='bwr', vmin=-1, vmax=1, transform=ccrs.PlateCarree())  \n",
    "    #calculate significance of trends\n",
    "    sig_p=xr.DataArray(data=p[i].values*np.sqrt((df-2)/(1-np.square(p[i].values))), \n",
    "                       dims=[\"lat\",\"lon'\"], coords=[lat, lon])\n",
    "    sig_p.plot.contourf(ax=ax,levels = [-1*t95, -1*t90, t90, t95], colors='none', \n",
    "                        hatches=['..', None, None, None, '..'], extend='both', add_colorbar=False, \n",
    "                        transform=ccrs.PlateCarree())\n",
    "    ax.set_extent([75, 290, -30, 30], crs=ccrs.PlateCarree())\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = True\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.xlocator = mticker.FixedLocator([-90, -135, 180, 135, 90])\n",
    "    gl.ylocator = mticker.FixedLocator([-20, -10, 0, 10, 20])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.xlabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    gl.ylabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.ylabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    ax.add_geometries([Ering], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth=2.5)\n",
    "    ax.add_geometries([Wring], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth =2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.title(var_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd3731-65e8-407c-a3e2-887739252e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap='BrBG' Brown to teal for precip dry/wet \n",
    "def gplot(p):\n",
    "    ax = fig.add_subplot(2,2,i+1, projection=ccrs.Robinson(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    plt.contourf(lon,lat,p[i],cmap='bwr', add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "    plt.pcolor(lon,lat,p[i], cmap='bwr', vmin=-1, vmax=1, transform=ccrs.PlateCarree())  \n",
    "    #calculate significance of trends\n",
    "    sig_p=xr.DataArray(data=p[i].values*np.sqrt((df-2)/(1-np.square(p[i].values))), \n",
    "                       dims=[\"lat\",\"lon'\"], coords=[lat, lon])\n",
    "    sig_p.plot.contourf(ax=ax,levels = [-1*t95, -1*t90, t90, t95], colors='none', \n",
    "                        hatches=['..', None, None, None, '..'], extend='both', add_colorbar=False, \n",
    "                        transform=ccrs.PlateCarree())\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = True\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.xlocator = mticker.FixedLocator([-90, -135, 180, 135, 90])\n",
    "    gl.ylocator = mticker.FixedLocator([-90, -60, -30, 0, 30, 60, 90])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.xlabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    gl.ylabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.ylabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    ax.add_geometries([Ering], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth=2.5)\n",
    "    ax.add_geometries([Wring], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth =2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.title(var_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edfd587-a8bc-4f57-a71d-4233288bbeed",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e416ee-6d4d-4216-b688-126478c09658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of what to plot\n",
    "controls_in = [cor_in, cor_in, cor_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a491262-de8c-4a52-b99b-95f897b977a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558112eb-34f4-4220-ba8f-17e22bd17faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "fig.dpi = 600\n",
    "for i in range(len(cors)):\n",
    "    trop_plot(cors)\n",
    "plt.suptitle('dD Correlation with ' + region, y =.65)\n",
    "#plt.rcParams['font.size'] = '24'\n",
    "plt.subplots_adjust(hspace=-1, wspace=0)\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "plt.tight_layout()\n",
    "plt.savefig(variable + \"glob_cor_post_anom.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce876291-6575-4160-94b7-839f24667793",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "fig.dpi = 600\n",
    "for i in range(len(cors)):\n",
    "    gplot(cors)\n",
    "plt.suptitle('dD Correlation with ' + region, y =.75)\n",
    "#plt.rcParams['font.size'] = '24'\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "plt.tight_layout()\n",
    "plt.savefig(variable + \"glob_cor_post_anom.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07916fb8-fb04-4aa8-9316-46c9dcf77de4",
   "metadata": {},
   "source": [
    "# Correlation with PWC - PI variable correlation with PI CNTL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce4af4-dd03-470d-b8cc-1838d426b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Map \n",
    "def globcntl_plot(p, pp):\n",
    "    #p = p[i] - cor_PSL[i] # subtract control run correlation \n",
    "    w = p[i] - pp\n",
    "    ax = fig.add_subplot(2,2,i+1, projection=ccrs.Robinson(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    plt.contourf(lon,lat,w,cmap='bwr', add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "    plt.pcolor(lon,lat,w, cmap='bwr', vmin=-0.2, vmax=0.2, transform=ccrs.PlateCarree())  \n",
    "    #calculate significance of trends\n",
    "    sig_p=xr.DataArray(data=p[i].values*np.sqrt((df-2)/(1-np.square(p[i].values))), \n",
    "                       dims=[\"lat\",\"lon'\"], coords=[lat, lon])\n",
    "    sig_p.plot.contourf(ax=ax,levels = [-1*t95, -1*t90, t90, t95], colors='none', \n",
    "                        hatches=['..', None, None, None, '..'], extend='both', add_colorbar=False, \n",
    "                        transform=ccrs.PlateCarree())\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = True\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.xlocator = mticker.FixedLocator([-90, -135, 180, 135, 90])\n",
    "    gl.ylocator = mticker.FixedLocator([-90, -60, -30, 0, 30, 60, 90])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.xlabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    gl.ylabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.ylabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    ax.add_geometries([Ering], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth=2.5)\n",
    "    ax.add_geometries([Wring], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth =2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.title(var_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6123b4bc-dd0f-4846-ad58-04e5a88c3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Map \n",
    "def tropcntl_plot(p, pp):\n",
    "    #p = p[i] - cor_PSL[i] # subtract control run correlation \n",
    "    w = p[i] - pp\n",
    "    ax = fig.add_subplot(2,2,i+1, projection=ccrs.Robinson(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    plt.contourf(lon,lat,w,cmap='bwr', add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "    plt.pcolor(lon,lat,w, cmap='bwr', vmin=-0.2, vmax=0.2, transform=ccrs.PlateCarree())  \n",
    "    #calculate significance of trends\n",
    "    sig_p=xr.DataArray(data=p[i].values*np.sqrt((df-2)/(1-np.square(p[i].values))), \n",
    "                       dims=[\"lat\",\"lon'\"], coords=[lat, lon])\n",
    "    sig_p.plot.contourf(ax=ax,levels = [-1*t95, -1*t90, t90, t95], colors='none', \n",
    "                        hatches=['..', None, None, None, '..'], extend='both', add_colorbar=False, \n",
    "                        transform=ccrs.PlateCarree())\n",
    "    ax.set_extent([75, 290, -30, 30], crs=ccrs.PlateCarree())\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = True\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.xlocator = mticker.FixedLocator([-90, -135, 180, 135, 90])\n",
    "    gl.ylocator = mticker.FixedLocator([-20, -10, 0, 10, 20])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.xlabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    gl.ylabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.ylabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    ax.add_geometries([Ering], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth=2.5)\n",
    "    ax.add_geometries([Wring], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth =2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.title(var_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9099d3d2-2607-4d74-917d-e097e43b3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "fig.dpi = 600\n",
    "for i in range(len(cors)):\n",
    "    tropcntl_plot(cors, cor_var_cntl)\n",
    "plt.suptitle('d18op' + ' Post Industrial PWC - PI CNTL Correlation', y =.95)\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(variable + \"glob_cor_post_anom.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92414b6c-b1b6-4750-a3b1-ea91b9652d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "fig.dpi = 600\n",
    "for i in range(len(cors)):\n",
    "    globcntl_plot(cors, cor_var_cntl)\n",
    "plt.suptitle('d18op' + ' Post Industrial PWC - PI CNTL Correlation', y =.95)\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(variable + \"glob_cor_post_anom.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a94323f-4a14-49dd-8744-30ca851c3f78",
   "metadata": {},
   "source": [
    "## 95% significance trend of grid points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa9b35-8503-4746-86b2-83e84255975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(r):\n",
    "    var_avg = r.mean(axis =0) \n",
    "    return(var_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e901f-fa0c-47bb-b21d-d3b7b7cbea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_trend(var,lon,lat,time,sig):\n",
    "    nlon=len(lon)\n",
    "    nlat=len(lat)\n",
    "    nt=len(time)\n",
    "    vart=zeros(nlat*nlon)\n",
    "    varp=zeros(nlat*nlon)\n",
    "    if len(var.shape)== 3:        \n",
    "        var1=reshape(var,(nt,nlat*nlon)) \n",
    "        for i in range(nlat*nlon):\n",
    "            v=var1[:,i]  \n",
    "            vart[i], intercept, r_value, varp[i], std_err=stats.linregress(time,v) # slope, intercept, r, p, std_error\n",
    "        vart=reshape(vart,(nlat,nlon))\n",
    "        varp=reshape(varp,(nlat,nlon))  \n",
    "        vt.append(vart)\n",
    "        vp.append(varp)\n",
    "        slope = np.stack(vt, axis=0)#, dim='ensemble')\n",
    "        pvalue = np.stack(vp, axis=0)#, dim='ensemble')\n",
    "        sig_pval = ma.masked_greater(pvalue, sig)\n",
    "        pval_avg = avg(sig_pval)\n",
    "        slope_avg = avg(slope)\n",
    "        return (slope, sig_pval, slope_avg, pval_avg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce6359d-fb76-46d4-b10f-bd3f2daa08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vt = []\n",
    "vp = []\n",
    "for ww in range(len(var_full)):\n",
    "    trend_full18, pval_full18, full_avg18, full_avgp18 = l_trend(anom_var18[ww,:,:,:].values,lon,lat,year,sig=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66cebf0-b7a6-4462-86e7-c19b9c00d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vt = []\n",
    "vp = []\n",
    "for ww in range(len(var_ghg)):\n",
    "    trend_ghg, pval_ghg, ghg_avg, ghg_avgp = l_trend(anom_var_ghg18[ww,:,:,:].values,lon,lat,year,sig=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b1806-3826-4c73-85e8-ab6c2a10ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vt = []\n",
    "vp = []\n",
    "for ww in range(len(var_oza)):\n",
    "    trend_oza, pval_oza, oza_avg, oza_avgp = l_trend(anom_var_oza18[ww,:,:,:].values,lon,lat,year,sig=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfdccda-547a-420b-8f0f-d7bfc1defded",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = [full_avg18, ghg_avg, oza_avg]\n",
    "lt_sig = [full_avgp18, ghg_avgp, oza_avgp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691480a3-1bc6-4987-87c8-078d1c5c75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trop_plot_trend(p,s):\n",
    "    ax = fig.add_subplot(2,2,i+1, projection=ccrs.Robinson(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    plt.contourf(lon,lat,p[i],cmap='bwr', add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "    plt.pcolor(lon,lat,p[i], cmap='bwr', vmin=-1, vmax=1, transform=ccrs.PlateCarree())  \n",
    "    plt.contourf(lon,lat,s[i], colors='none',  hatches=['..', None, None, None, '..'], extend='both', add_colorbar=False, \n",
    "                        transform=ccrs.PlateCarree())\n",
    "    ax.set_extent([75, 290, -30, 30], crs=ccrs.PlateCarree())\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = True\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.xlocator = mticker.FixedLocator([-90, -135, 180, 135, 90])\n",
    "    gl.ylocator = mticker.FixedLocator([-20, -10, 0, 10, 20])\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.xlabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    gl.ylabel_style = {'size': 25, 'color': 'gray'}\n",
    "    gl.ylabel_style = {'size': 12.5,'color': 'black', 'weight': 'bold'}\n",
    "    ax.add_geometries([Ering], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth=2.5)\n",
    "    ax.add_geometries([Wring], ccrs.PlateCarree(), facecolor='none', edgecolor='dimgrey', linewidth =2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.title(var_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0c4b8-dcfb-46eb-a3a4-46bc6e76dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_trend_plot(t, p):\n",
    "    ax = fig.add_subplot(2,3,i+1, projection=ccrs.Robinson(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    plt.contourf(lon,lat,t[i],cmap='bwr', transform=ccrs.PlateCarree()) \n",
    "    plt.pcolor(lon,lat,t[i], cmap='bwr', vmin=-.001, vmax=.001, transform=ccrs.PlateCarree())    \n",
    "    #plt.colorbar(orientation='horizontal')\n",
    "    cs = ax.contourf(lon,lat, p[i], colors='none' ,hatches=[\".\"],extend='lower', transform=ccrs.PlateCarree())\n",
    "    ax.set_aspect('equal')\n",
    "    plt.rcParams['font.size'] = '14'\n",
    "    plt.title(var_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a8c82-8756-455a-9335-6fd0158531b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "fig.dpi = 600\n",
    "for i in range(len(lt)):\n",
    "    glob_trend_plot(lt, lt_sig)\n",
    "plt.suptitle('dD Correlation with ' + region, y =.65)\n",
    "#plt.rcParams['font.size'] = '24'\n",
    "plt.subplots_adjust(hspace=-1, wspace=0)\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "plt.tight_layout()\n",
    "plt.savefig(variable + \"glob_cor_post_anom.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d9acad-6fef-465f-8f26-b38ca6ea7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "fig.dpi = 600\n",
    "for i in range(len(lt)):\n",
    "    trop_plot_trend(lt, lt_sig)\n",
    "plt.suptitle('dD Linear Trend with ' + region, y =.65)\n",
    "#plt.rcParams['font.size'] = '24'\n",
    "plt.subplots_adjust(hspace=-1, wspace=0)\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "plt.tight_layout()\n",
    "plt.savefig(variable + \"glob_cor_post_anom.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c886251-34a0-4a63-b2b8-6ab0ff832c44",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42985b-6f35-4c2f-945a-4bcf023a42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "index_var = compute_index(anom_var18).mean(dim = 'ensemble')\n",
    "index_var_ghg = compute_index(anom_var_ghg18).mean(dim = 'ensemble')\n",
    "#index_lulc = compute_index(anom_index_lulc)\n",
    "index_var_oza = compute_index(anom_var_oza18).mean(dim = 'ensemble')\n",
    "index_var_cntl = compute_index(anom_var_cntl18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509539cb-7d14-46c4-996d-acf6cbdef579",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "index_var = compute_index(anom_index).mean(dim = 'ensemble')\n",
    "index_var_ghg = compute_index(anom_index_ghg).mean(dim = 'ensemble')\n",
    "#index_lulc = compute_index(anom_index_lulc)\n",
    "index_var_oza = compute_index(anom_index_oza).mean(dim = 'ensemble')\n",
    "index_var_cntl = compute_index(anom_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3aa5b9-166a-438b-9e6f-40e201c8ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_list = [index_var, index_var_ghg, index_var_oza]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af352f4d-cc5f-499e-9bab-90ae4f1f0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1/12  # In years\n",
    "t_oza = np.arange(0,1872)*dt +1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4062a83-20d7-4877-a730-ec58bc7d21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_post = ['FULL', 'GHG','OZA'] # OZA Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dba895-6ede-4cc4-82ef-451d2881cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['green', 'blue','darkorange']\n",
    "colors_line = ['green', 'blue','orange']\n",
    "colors_ribbon = ['lightgreen', 'lightblue','lightyellow']\n",
    "lent_post = len(ts_list)\n",
    "variable = 'dD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe5b12-4024-47a0-90ce-3527c122c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_post(r):\n",
    "   # ax = fig.add_subplot(sharex=True, sharey=False)\n",
    "    post = r[i].sel(time = slice('1850-01-01', '2005-12-01'))\n",
    "    res = stats.linregress(t_oza,post)\n",
    "    roll_avg = post.rolling(time=120, center=True).mean()\n",
    "    ax.set_title(var_post[i])\n",
    "    #ax.set_ylim([-.4,.4])\n",
    "    plt.rcParams['font.size'] = '30'\n",
    "    plt.plot(t_oza,roll_avg, color = colors[i], label = var_post[i])\n",
    "    plt.plot(t_oza, (res.intercept + res.slope*t_oza), colors_line[i])\n",
    "    plt.fill_between(t_oza, roll_avg + roll_avg.std(),roll_avg - roll_avg.std(),  edgecolor= colors_ribbon[i], facecolor=colors_ribbon[i], alpha=1)\n",
    "    plt.ylabel('dD (per mille)', fontsize = '28')\n",
    "    fig.suptitle('dD Difference East (210-270) - West (90-150) Anomalies')\n",
    "    #print('Slope Pre' + var_post[i] + res.slope)\n",
    "    #print('p-value' +var_post[i] + res.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a812765-471c-4ee0-85e7-95b15bd11f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Time\n",
    "fig = plt.figure(figsize=(40,20))\n",
    "for i in range(lent_post):\n",
    "    roll_post(ts_list)\n",
    "    plt.ylim(-5,5)#\n",
    "plt.xlabel('Year', fontsize = '30')\n",
    "plt.rcParams['font.size'] = '30'\n",
    "plt.rcParams['font.family']= 'sans-serif'\n",
    "plt.suptitle(variable +' 10 Year Rolling Average ' + region , y = 0.9, fontsize = '35',fontweight=\"bold\")\n",
    "#plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "plt.legend(mode = \"expand\", loc = 'lower center', bbox_to_anchor=(0.25,-0.25,0.5, -0.75), ncol =5)\n",
    "plt.savefig(variable + \"roll_post_mc.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024a",
   "language": "python",
   "name": "npl-2024a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
