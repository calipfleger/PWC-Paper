{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d5f9e8-d274-4588-b15e-d92b82e9974d",
   "metadata": {},
   "source": [
    "# Cali Pfleger\n",
    "## 05/25/2024\n",
    "- Model iCESM and CESM Last Millenium Ensemble \n",
    "- Climate System: Pacific Walker Circulation \n",
    "- Index: Sea Level Pressure Index (hPa)\n",
    "- Variable: d18Op (0/00) (per mille)\n",
    "- Time period: 1850-2005 \n",
    "- Forcings: Full, GHG, LULC, OZA\n",
    "\n",
    "# Calculations:\n",
    "- Index Time Series (trend line, p-value, standered error (+1/-1) ribbon and ensmeble average)\n",
    "- Climatological Average Maps\n",
    "- Global Average Time Series (standered error ribbon and ensmeble average)\n",
    "- Linear Trend Maps (95% CI significance stippling)- \n",
    "- Correlation with Index Maps (95% CI significance stippling)- \n",
    "- Effect of Forcing Maps (Correlation - PI Control Run Corrleation)\n",
    "GCM Changes in Vertical Velocity (ω) Across the Tropical Pacific.\n",
    "iCAM5 = 2xCO2 Experiment minus Modern Control, Meridional Mean (−20 to 20 latitude).Change in vertical velocity (ω) in the experiment minus the control in color filled contour plot. Black contour lines show control simulation. Sign convention is negative = upward motion, positive = downward motion. Thus, red colors in Western Pacific indicate a reduction in the magnitude of the negative values in the control compared to the experiment. Blue colors indicate less positive values in the experiment compared to the control, or less downward motion.\n",
    "\n",
    "- Vertical Profile Maps (dD(per mille), omega, temperature (C), pressure (hPa))\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2288e0-a58e-49d1-a183-19b386ccec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters and Naming \n",
    "model ='Model iCESM and CESM '\n",
    "region = 'PWC Index ' # 'Eastern Pacific ' 'Western Pacific ' \n",
    "variable = 'SLP' #Sea Level Pressure\n",
    "period = \"Post Industrial\"# \"Full LME\" #\"Pre Industrial\",\n",
    "timep = \"_post\"# \"_pre\" # \n",
    "var_name = ['Full', 'GHG', 'LULC','OZA']#, 'ANTHRO']\n",
    "timep_title = \"Post Industrial\"#'Pre Industrial' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55acdd08-5b78-41fa-adfd-aefb773cfd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index Box Parameters \n",
    "## Make geom for E and W PWC index boxes\n",
    "from shapely import geometry\n",
    "from shapely.geometry.polygon import LinearRing, Polygon\n",
    "Elats = [-5, -5, 5, 5]\n",
    "Elons = [90, 150, 150,90]\n",
    "Ering = LinearRing(list(zip(Elons, Elats)))\n",
    "Wlats = [-5, -5, 5, 5]\n",
    "Wlons = [-150,-90,-90,-150]\n",
    "Wring = LinearRing(list(zip(Wlons, Wlats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e577652-fbcf-4e9b-a427-cbfba6709d37",
   "metadata": {},
   "source": [
    "# Read in Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbbb20a-b42f-4b34-8bc5-ae3339b35a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b57fe4d-607a-47d8-aac2-ef26c2f869e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/glade/u/home/calipfleger/stats/PWC_Paper/pwc_clean'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39488f12-00c9-43aa-8314-1fad9c1e35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir_atm = '/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/'\n",
    "file_prefix= '.cam.h0.' \n",
    "i_model = '/b.ie12.B1850C5CN.f19_g16.LME.' ## read in 2&3 iLME Ensembles \n",
    "i_model1 = '/b.ie12.B1850CN.f19_g16.' ## read in iLME ens 1\n",
    "model = '/b.e11.BLMTRC5CN.f19_g16.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb48652-e543-4392-a91f-0d28de7dcc05",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd227382-ef11-4508-a46f-1f9689f9a1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pprint import pprint\n",
    "#import nctoolkit\n",
    "# colors for lines (color blind friendly colors: https://gist.github.com/thriveth/8560036)\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "import matplotlib as mpl  # # Plotting\n",
    "import matplotlib.pyplot as plt  # python plotting package\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from colorspacious import cspace_converter\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "cmaps = OrderedDict()\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LATITUDE_FORMATTER, LONGITUDE_FORMATTER\n",
    "from cartopy.mpl.ticker import LatitudeFormatter, LongitudeFormatter\n",
    "from colorspacious import cspace_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1e0f6f-4aab-4f3b-8439-a1cf3c70a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cftime\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "from scipy import stats\n",
    "from netCDF4 import Dataset as nc\n",
    "from netCDF4 import num2date\n",
    "import netCDF4\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt #python plotting package\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as mcolors\n",
    "from colorspacious import cspace_converter\n",
    "from collections import OrderedDict\n",
    "cmaps = OrderedDict()\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "#import nctoolkit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.feature as cpf\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from shapely import geometry\n",
    "from collections import namedtuple\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107bf4d-ff46-4908-8364-101155642081",
   "metadata": {},
   "source": [
    "# Calculations and Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1284a371-3256-4676-a89f-1012b2d0cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CESM converting month 01 to January \n",
    "from itertools import product\n",
    "from cftime import DatetimeNoLeap\n",
    "year = np.linspace(0,1872, 1872) \n",
    "dates = [DatetimeNoLeap(year, month, 1) for year, month in product(range(1850, 2006), range(1, 13))]\n",
    "da = xr.DataArray(np.arange(1872), coords=[dates], dims=['time'], name='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c422e8b-58c5-41b7-b040-e4b0399f5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set control year \n",
    "i_cntlyear = np.linspace(0,2400, 2400) \n",
    "i_cntldates = [DatetimeNoLeap(i_cntlyear, month, 1) for i_cntlyear, month in product(range(650, 850), range(1, 13))]\n",
    "i_cntlda =xr.DataArray(np.arange(2400), coords=[i_cntldates], dims=['time'], name='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "018a0827-8630-4f46-b100-02bae234cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grid cell weighting to acount for grid cells in extratropics \n",
    "def weights(w):\n",
    "    coslat = np.cos(np.deg2rad(w.lat)) #  Take the cosine of latitude (first converting to radians)\n",
    "    weight_factor = coslat / coslat.mean(dim='lat')#  And divide by its mean value\n",
    "    computed_weight = w * weight_factor # .mean(dim=('time', 'lon', 'lat'))\n",
    "    return computed_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "784be969-55ce-4660-92e9-83d4113178ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Ensemble average \n",
    "def ensav(e):\n",
    "    ens_avg = e.mean(dim = 'ensemble')\n",
    "    return ens_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b4f4988-d311-42f0-954e-52d925d8de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Dr. Samantha Stevenson UCSB\n",
    "#mask_lon = (mytos.lon >= regbox[2]) & (mytos.lon <= regbox[3])\n",
    "#mask_lat = (mytos.lat >= regbox[0]) & (mytos.lat <= regbox[1])\n",
    "#hsst=mytos.where(mask_lon & mask_lat, drop=True).squeeze().isel(lev=23).isel(lev=23).isel(lev=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15f4b275-a161-4c87-a35b-096d064a752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWC Index\n",
    "def compute_index(c):\n",
    "    east = c.sel(lat=slice(-5,5), lon=slice(210,270))\n",
    "    west = c.sel(lat=slice(-5,5), lon=slice(90,150))\n",
    "    #east = c.sel(lat=slice(-10,10), lon=slice(190,250))\n",
    "    #west = c.sel(lat=slice(-10,10), lon=slice(90,150))\n",
    "    avg_east = east.mean(('lat', 'lon'))\n",
    "    avg_west =  west.mean(('lat', 'lon'))\n",
    "    clim_index = (avg_east- avg_west).compute()\n",
    "    return clim_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0df8a96-c581-4210-b24b-3837395a7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for meridional mean and lat lon range \n",
    "def mer(m):\n",
    "    #m_we = weights(m)\n",
    "    mer_lat= m.sel(lat=slice(-20, 20)).mean(dim='lat')\n",
    "    mer_lon = mer_lat.sel(lon=slice(110, 270))\n",
    "    mer_clim = clim(mer_lon)\n",
    "    mer_time = mer_clim.mean(dim='time')\n",
    "    mer_avg = mer_time#.mean(dim = 'ensemble')\n",
    "    return mer_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d485c31-355b-41c0-b400-4eab3b7d98fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Anomaly relative to Climatology for variable \n",
    "def clim(tc): \n",
    "    #units = tc/100 #convert d18O \n",
    "    #convert precip 1000*24*3600\n",
    "    c = tc.assign_coords({'time':(da.time)}) #convert time dimestion to have 01 be january \n",
    "    clim_var = c.groupby('time.month').mean('time') #calculate monthly climatology\n",
    "    clim_anom = c.groupby('time.month') - clim_var # calculate the anomaly relative to the climatology \n",
    "    #anom_weights = weights(clim_anom) #weight functino to account for lat grid size \n",
    "    return  clim_anom #return the anomaly calcuated by the anomaly with time and lat conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7198985-f02f-4fe3-b794-1d561ea01780",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Anomaly relative to Climatology for variable \n",
    "def clim_cntl(tc): \n",
    "    #units = tc/100 #convert d18O \n",
    "    #convert precip 1000*24*3600\n",
    "    c = tc.assign_coords({'time':(i_cntlda.time)}) #convert time dimestion to have 01 be january \n",
    "    clim_var = c.groupby('time.month').mean('time') #calculate monthly climatology\n",
    "    clim_anom = c.groupby('time.month') - clim_var # calculate the anomaly relative to the climatology \n",
    "    #anom_weights = weights(clim_anom) #weight functino to account for lat grid size \n",
    "    return clim_anom #return the anomaly calcuated by the anomaly with time and lat conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e8754a-9d42-4cbb-99fa-1a87baac1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Ensemble average \n",
    "def clim_avg(ca):\n",
    "    #convert precip 1000*24*3600\n",
    "    c = ca.assign_coords({'time':(da.time)})\n",
    "    time_avg = c.mean('time')\n",
    "    ens_avg = time_avg.mean(dim = 'ensemble')\n",
    "    return ens_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acb33cb9-525e-4f7e-a87b-ea5f837be920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Correlation Coefficent using xr.corr \n",
    "def cor(g,t):\n",
    "    ds= []\n",
    "    fcor =xr.corr(g,t, dim = 'time') # g is the global data set and t is the time series index \n",
    "    ds.append(fcor) # add correlation coeefiecent to dataset \n",
    "    cords= xr.concat(ds, dim='ensemble')  # create ensmenble dimesion for correlation coeeficent \n",
    "    cor_avg = cords.mean('ensemble') # calculate ensemble average for correlation coeeficent \n",
    "    return cor_avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31738d25-da2e-44e8-9308-67cbced61f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_trend(var,lon,lat,time,sig):\n",
    "    nlon=len(lon)\n",
    "    nlat=len(lat)\n",
    "    nt=len(time)\n",
    "    vart=zeros(nlat*nlon)\n",
    "    varp=zeros(nlat*nlon)\n",
    "    if len(var.shape)== 3:        \n",
    "        var1=reshape(var,(nt,nlat*nlon)) \n",
    "        for i in range(nlat*nlon):\n",
    "            v=var1[:,i]  \n",
    "            vart[i], intercept, r_value, varp[i], std_err=stats.linregress(time,v) # slope, intercept, r, p, std_error\n",
    "        vart=reshape(vart,(nlat,nlon))\n",
    "        varp=reshape(varp,(nlat,nlon))  \n",
    "        vt.append(vart)\n",
    "        vp.append(varp)\n",
    "        slope = np.stack(vt, axis=0)#, dim='ensemble')\n",
    "        pvalue = np.stack(vp, axis=0)#, dim='ensemble')\n",
    "        sig_pval = ma.masked_greater(pvalue, sig)\n",
    "        pval_avg = avg(sig_pval)\n",
    "        slope_avg = avg(slope)\n",
    "        return (slope, sig_pval, slope_avg, pval_avg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d354ab3-a03d-4aee-9154-dd76dd50d908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Files: /b.e11.BLMTRC5CN.f19_g16.Post Industrial PWC Index \n"
     ]
    }
   ],
   "source": [
    "print('Index Files: ' +  model + period ,''+ region )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de077c-c0e6-419f-a995-63e0c48ae01f",
   "metadata": {},
   "source": [
    "# Read in Index Files: TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b7ea605-23b3-4d1a-81a1-d62ba557c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'OMEGA' #set output variable name for reading in file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63d81d83-dd67-46b4-ba87-79c9b439bd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.27s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.32it/s]\n",
      "100%|██████████| 9/9 [00:23<00:00,  2.61s/it]\n",
      "100%|██████████| 4/4 [00:14<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 17s, sys: 11.2 s, total: 3min 29s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ens = '' #Full forcing ensemble \n",
    "file_suffix= '.185001-200512.nc'\n",
    "ds = []# initialise array:\n",
    "for member in tqdm(range(1,2)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model1+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "    ds.append(member)\n",
    "    \n",
    "for member in tqdm(range(2,3+1)): #loop to read in the 1-9 ensemble members \n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix # set file path \n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model +ens +'00' +file).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "    ds.append(member)\n",
    "\n",
    "for member in tqdm(range(1,9+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "    ds.append(member)\n",
    "    \n",
    "for member in tqdm(range(10,13+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ model+ens +'0'+file).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "    ds.append(member)\n",
    "    \n",
    "var_full=  xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)})#/100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6293ec2d-d12c-4834-b866-e9bcab4c8431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.47it/s]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 26.7 s, total: 2min 10s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ens = 'GHG.'  # GHG ensemble \n",
    "file_suffix= '.185001-200512.nc'\n",
    "ds = [] # initialise array:\n",
    "for member in tqdm(range(1,2)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "    ds.append(member)\n",
    "for member in tqdm(range(3,4+1)): #add in 4th ensmble when permission is not denied \n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "    ds.append(member)\n",
    "for member in tqdm(range(1,3+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ model +ens +'00' +file).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "var_ghg =  xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)})#/100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fe5b3d5-f38d-45bf-a34d-f465b38807e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:14<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 6.2 s, total: 1min 56s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ens = 'O3AER.'\n",
    "file_suffix= '.185001-200512.nc'\n",
    "ds = []\n",
    "for member in (1,3,4,5):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm + var+ i_model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "    ds.append(member)\n",
    "\n",
    "ens = 'OZONE_AER.'\n",
    "for member in tqdm(range(1,5+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ model+ ens + '00'+file).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "    ds.append(member)\n",
    "\n",
    "var_oza= xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)})#/100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c5492f5-9962-4147-926a-2287b47099f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:01,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 4.02 s, total: 1min 18s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ens = 'LULC.'  #Lulc ensemble \n",
    "file_suffix= '.169001-200512.nc'\n",
    "ds = []\n",
    "for member in tqdm(range(1,3+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ i_model+ ens + '00'+file).sel(time = slice('1850-02-01', '2006-01-01')).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "    ds.append(member)\n",
    "ens = 'LULC_HurttPongratz.'\n",
    "file_suffix= '.185001-200512.nc'\n",
    "for member in tqdm(range(1,3+1)):\n",
    "    id = str(member)\n",
    "    file = id+file_prefix+var+ file_suffix\n",
    "    member = xr.open_dataset(basedir_atm+ var+ model+ ens + '00'+file).sel(time = slice('1850-02-01', '2006-01-01')).sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()\n",
    "    ds.append(member)\n",
    "var_lulc = xr.concat(ds, dim='ensemble').sel(time = slice('1850-02-01', '2006-01-01')).assign_coords({'time':(da.time)})#/100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8758b70-e776-4fd8-99c2-a732eb1bb7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "icntl_index = xr.open_dataset('/glade/campaign/cesm/collections/cesmLME/CESM-CAM5-LME/atm/proc/tseries/monthly/OMEGA/b.ie12.B1850CN.f19_g16.850cntl.001.cam.h0.OMEGA.065001-084912.nc').sel(lat=slice(-35,35),lon=slice(75,290)).OMEGA.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16281065-bf94-4402-82ec-2d957fbdd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'OMEGA18'\n",
    "var_full.isel(lev =18).to_netcdf(variable+'full.nc')\n",
    "var_ghg.isel(lev =18).to_netcdf(variable+'ghg.nc')\n",
    "var_oza.isel(lev =18).to_netcdf(variable+'oza.nc')\n",
    "var_lulc.isel(lev =18).to_netcdf(variable+'lulc.nc')\n",
    "icntl_index.isel(lev =18).to_netcdf(variable+'cntl.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a25e7a-f6cb-4d3b-ae1b-74bb8856baab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024a",
   "language": "python",
   "name": "npl-2024a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
